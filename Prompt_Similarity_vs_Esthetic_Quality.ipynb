{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "62-fEt6zKElK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f8c324-a876-45b4-c559-81b5786f12bb"
      },
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy) (0.2.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-v6i_pa10\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-v6i_pa10\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (0.15.1+cu118)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->clip==1.0) (0.2.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->clip==1.0) (16.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->clip==1.0) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "print(clip.available_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbXDEPwHUYKr",
        "outputId": "5650a25e-979a-496d-ba2b-a876476d96a0"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLf1HrjgKTKB"
      },
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "file_list = glob.glob(\"/content/drive/MyDrive/AI/*.png\")\n",
        "file_list.sort()"
      ],
      "metadata": {
        "id": "1Bl5XeosL4zl"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_list[96:96+12])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwpYNn7-MOMN",
        "outputId": "502d89c0-1a93-4872-ce0b-2d4f09f5885d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFont, ImageDraw\n",
        "fnt = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', 40)\n",
        "dimensions = {\"Abstract\": (512, 512), \"Landscape\": (512, 512), \"Portrait\": (512, 512),\n",
        "              \"Still Life\": (512, 512), \"Watercolor\": (512, 512), \"Character Design\": (512, 512),\n",
        "              \"Portraits\": (512, 512)}\n",
        "\n",
        "\n",
        "for i, f in enumerate(file_list):\n",
        "  if \"V2\" in f:\n",
        "    sd = \"V2\"\n",
        "  elif \"V3\" in f:\n",
        "    sd = \"V3\"\n",
        "  elif \"V4\" in f:\n",
        "    sd = \"V4\"\n",
        "  elif \"V5\" in f:\n",
        "    sd = \"V5\"\n",
        "  elif \"NIJI4\" in f:\n",
        "    sd = \"NIJI4\"\n",
        "  elif \"NIJI5\" in f:\n",
        "    sd = \"NIJI5\"\n",
        "  elif \"NIJI EX\" in f:\n",
        "    sd = \"NIJI EX\"\n",
        "  elif \"NIJI CU\" in f:\n",
        "    sd = \"NIJI CU\"\n",
        "  else:\n",
        "    sd = \"UNKNOWN\"\n",
        "  c = i % 4\n",
        "\n",
        "  print(f)\n",
        "  parts = f.split(\"/\")\n",
        "\n",
        "  subject = \"Portraits\"\n",
        "if \"wise white haired magic wizard\" in f:\n",
        "    prompt = \"A wise white haired magic wizard Portraits\"\n",
        "elif \"Caribbean pirate\" in f:\n",
        "    prompt = \"A domineering Caribbean pirate Portraits by Hiroshi Yoshida\"\n",
        "elif \"youth tide man\" in f:\n",
        "    prompt = \"pastel painting of a Handsome youth tide man Portraits by Mucha+Da Vinci\"\n",
        "elif \"beautiful girl in the sun\" in f:\n",
        "    prompt = \"A beautiful girl in the sun Portraits by Childe Hassam+Edgar Payne+sorolla\"\n",
        "else:\n",
        "    prompt = \"Unknown Prompt\"\n",
        "dims = dimensions[subject]\n",
        "img = Image.open(f)\n",
        "img_resized = img.resize(dims)\n",
        "draw = ImageDraw.Draw(img_resized)\n",
        "\n",
        "if sd == \"V2\":\n",
        "    draw.text((3, dims[1]-41), sd+str(c), font=fnt, fill=(255, 127, 14, 255))\n",
        "elif sd == \"V3\":\n",
        "    draw.text((3, dims[1]-41), sd+str(c), font=fnt, fill=(31, 119, 180, 255))\n",
        "elif sd == \"V4\":\n",
        "    draw.text((3, dims[1]-41), sd+str(c), font=fnt, fill=(44, 160, 44, 255))\n",
        "elif sd == \"V5\":\n",
        "    draw.text((3, dims[1]-41), sd+str(c), font=fnt, fill=(214, 39, 40, 255))\n",
        "elif sd == \"NIJI4\":\n",
        "    draw.text((3, dims[1]-41), sd+str(c), font=fnt, fill=(148, 103, 189, 255))\n",
        "elif sd == \"NIJI5\":\n",
        "    draw.text((3, dims[1]-41), sd+str(c), font=fnt, fill=(140, 86, 75, 255))\n",
        "elif sd == \"NIJI EX\":\n",
        "    draw.text((3, dims[1]-41), sd+str(c), font=fnt, fill=(227, 119, 194, 255))\n",
        "else:  # sd == \"NIJI CU\"\n",
        "   draw.text((3, dims[1]-41), sd+str(c), font=fnt, fill=(127, 127, 127, 255))\n",
        "\n",
        "\n",
        "draw.text((6, dims[1]-44), sd+str(c), font=fnt, fill=(255, 255, 255, 255))\n",
        "\n",
        "if c == 0:\n",
        "    w = dims[0]*2+10\n",
        "    h = dims[1]*2+10\n",
        "    im = Image.new(mode = \"RGB\", size = (w, h), color = (255, 255, 255))\n",
        "    Image.Image.paste(im, img_resized, (0, 0))\n",
        "\n",
        "elif c == 1:\n",
        "    Image.Image.paste(im, img_resized, (dims[0]+10, 0))\n",
        "elif c == 2:\n",
        "    Image.Image.paste(im, img_resized, (0, dims[1]+10))\n",
        "else:\n",
        "    Image.Image.paste(im, img_resized, (dims[0]+10, dims[1]+10))\n",
        "    im.save(\"/content/drive/MyDrive/AI\"+subject+\"/\"+prompt+\"_\"+sd+\".jpg\", quality=95)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "N95n9NpyYnXK",
        "outputId": "5142631a-c0b9-40a3-8ba0-e2e712d2e98f"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI/v201.png\n",
            "/content/drive/MyDrive/AI/v202.png\n",
            "/content/drive/MyDrive/AI/v203.png\n",
            "/content/drive/MyDrive/AI/v204.png\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-7a14849fd3a7>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_resized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_resized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AI\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mpaste\u001b[0;34m(self, im, box, mask)\u001b[0m\n\u001b[1;32m   1574\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misImageType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"RGB\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RGBa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m                     \u001b[0;31m# should use an adapter for this!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'mode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eMArrjDJNuEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "prompt_similarities = []\n",
        "esthetic_qualities = []\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "start = 96\n",
        "\n",
        "for i, f in enumerate(file_list[start:start+12]):\n",
        "  if \"V2\" in f:\n",
        "    sd = \"V2\"\n",
        "  elif \"V3\" in f:\n",
        "    sd = \"V3\"\n",
        "  elif \"V4\" in f:\n",
        "    sd = \"V4\"\n",
        "  elif \"V5\" in f:\n",
        "    sd = \"V5\"\n",
        "  elif \"NIJI4\" in f:\n",
        "    sd = \"NIJI4\"\n",
        "  elif \"NIJI5\" in f:\n",
        "    sd = \"NIJI5\"\n",
        "  elif \"NIJI EX\" in f:\n",
        "    sd = \"NIJI EX\"\n",
        "  elif \"NIJI CU\" in f:\n",
        "    sd = \"NIJI CU\"\n",
        "  else:\n",
        "    sd = \"UNKNOWN\"\n",
        "  c = i % 4\n",
        "\n",
        "  labels.append(sd+str(c))\n",
        "  parts = f.split(\"/\")\n",
        "  subject = parts[5]\n",
        "  prompt = parts[6]\n",
        "  # print(sd, c, subject, prompt, f)\n",
        "\n",
        "  img = Image.open(f)\n",
        "  img_resized = img.resize((336, 336))\n",
        "  # display(img_resized)\n",
        "\n",
        "  image = preprocess(img_resized).unsqueeze(0).to(device)\n",
        "  text = clip.tokenize([\"fake art\", \"real art\", \"bad art\", \"good art\", \n",
        "    prompt]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    image_features = model.encode_image(image)\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    embeddings.append(image_features.flatten().cpu().tolist())\n",
        "    text_features = model.encode_text(text)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "    similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n",
        "\n",
        "  fake = similarity[0][0]\n",
        "  real = similarity[1][0]\n",
        "  bad = similarity[2][0]\n",
        "  good = similarity[3][0]\n",
        "  esthetic_quality = (real-fake) + (good-bad)\n",
        "\n",
        "  prompt_similarity = similarity[4][0]\n",
        "\n",
        "  prompt_similarities.append(esthetic_quality)\n",
        "  esthetic_qualities.append(prompt_similarity)\n",
        "\n",
        "  print(\"{:7.4f}\".format(prompt_similarity), \"{:7.4f}\".format(esthetic_quality), f)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(7, 7), dpi=80)\n",
        "\n",
        "plt.xlabel(\"matches less <--    Prompt Similarity    --> matches more\", fontsize=12)\n",
        "plt.ylabel(\"lower <--    Esthetic Quality    --> higher\", fontsize=12)\n",
        "plt.scatter(esthetic_qualities[8:12], prompt_similarities[8:12], s=100, label=\"Midjourney\")\n",
        "plt.scatter(esthetic_qualities[4:8], prompt_similarities[4:8], s=100, label=\"Dall-E\")\n",
        "plt.scatter(esthetic_qualities[0:4], prompt_similarities[0:4], s=100, label=\"Stable Diffusion\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "\n",
        "for i, txt in enumerate(labels):\n",
        "  ax.annotate(txt, (esthetic_qualities[i]+0.0009, prompt_similarities[i]-0.0003))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DUVv6fRJMfn8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}